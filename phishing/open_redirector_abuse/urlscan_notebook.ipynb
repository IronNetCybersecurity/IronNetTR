{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "religious-march",
   "metadata": {},
   "source": [
    "# Notebook for retrieving final destination phishing domains from urlscan.io \n",
    "\n",
    "## Requirements\n",
    "* Python Libraries\n",
    "  * Pandas\n",
    "  * Requests\n",
    "* urlscan.io API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "from requests import get\n",
    "from getpass import getpass\n",
    "from urllib.parse import quote\n",
    "from json import loads\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-shaft",
   "metadata": {},
   "source": [
    "## Get urlscan.io data\n",
    "\n",
    "### REGEXs\n",
    "We have 2 REGEX queries that will find all the relevant final destination (FD) phishing domains with high accuracy. The first 2 queries are not combined due to limitations in how many results you can obtain at one time from the urlscan API. \n",
    "\n",
    "#### REGEX 1: All FD URLs abusing reCAPTCHA with `-`\n",
    "**Base REGEX**\n",
    "\n",
    "```\n",
    "^(http)(s)?:\\/\\/([a-z0-9]+\\.)?[a-z0-9]{1,}\\-[a-z0-9]{1,}\\.[a-z]+\\/(main|jump)\\/$\n",
    "```\n",
    "\n",
    "**urlscan.io Query**\n",
    "\n",
    "```\n",
    "filename:\"/recaptcha/api.js\" AND page.url.keyword:/(http)(s)?:\\/\\/([a-z0-9]+\\.)?[a-z0-9]{1,}\\-[a-z0-9]{1,}\\.[a-z]+\\/(main|jump)\\//\n",
    "```\n",
    "\n",
    "\n",
    "#### REGEX 2: All FD URLs abusing reCAPTCHA without `-`\n",
    "**Base REGEX**\n",
    "\n",
    "```\n",
    "^(http)(s)?:\\/\\/([a-z0-9]+\\.)?([a-z]|[0-9])+\\.[a-z]+\\/(main|jump)\\/$\n",
    "```\n",
    "\n",
    "**urlscan.io Query**\n",
    "```\n",
    "filename:\"/recaptcha/api.js\" AND page.url.keyword:/(http)(s)?:\\/\\/([a-z0-9]+\\.)?([a-z]|[0-9])+\\.[a-z]+\\/(main|jump)\\//\n",
    "```\n",
    "\n",
    "\n",
    "### Hash queries\n",
    "\n",
    "#### ExRobotos Phishing URLs Group 1\n",
    "\n",
    "**urlscan.io Query**\n",
    "```\n",
    "hash:35283bce87f120b3df83722176e4c6684f2e64088aa24f357ac7530b54754beb\n",
    "```\n",
    "\n",
    "#### ExRobotos Phishing URLs Group 2\n",
    "\n",
    "**urlscan.io Query**\n",
    "```\n",
    "hash:ce1441121feb1441dcd78d618caa8228432271f6671e896c8a753af3dd679623 AND hash:105c03d3360cdb953585482374b2cc953d090741037502b0609629f5bb0135b7 AND hash:f32a760f15530284447282af5c7d0825babf8bc4739e073928f6128830819f7a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-diagnosis",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "Using python requests can sometimes be slow, so if you are using curl, you can also load results from a file.\n",
    "The first code block uses Python's requests library while the next code block loads from a file.\n",
    "\n",
    "#### Python Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-latex",
   "metadata": {},
   "source": [
    "**Enter API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max results here!\n",
    "max_results = 10000\n",
    "base_url = f'https://urlscan.io/api/v1/search/?size={max_results}&q='\n",
    "regex_one_query = quote(\n",
    "    'filename:\"/recaptcha/api.js\" AND page.url.keyword:/(http)(s)?:\\/\\/([a-z0-9]+\\.)?[a-z0-9]{1,}\\-[a-z0-9]{1,}\\.[a-z]+\\/(main|jump)\\//'\n",
    ")\n",
    "regex_two_query = quote(\n",
    "    'filename:\"/recaptcha/api.js\" AND page.url.keyword:/(http)(s)?:\\/\\/([a-z0-9]+\\.)?([a-z]|[0-9])+\\.[a-z]+\\/(main|jump)\\//'\n",
    ")\n",
    "exrobotos_group_one = quote(\n",
    "    'hash:35283bce87f120b3df83722176e4c6684f2e64088aa24f357ac7530b54754beb'\n",
    ")\n",
    "exrobotos_group_two = quote(\n",
    "    'hash:ce1441121feb1441dcd78d618caa8228432271f6671e896c8a753af3dd679623 AND hash:105c03d3360cdb953585482374b2cc953d090741037502b0609629f5bb0135b7 AND hash:f32a760f15530284447282af5c7d0825babf8bc4739e073928f6128830819f7a'\n",
    ")\n",
    "headers = {'api-key': api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_one_results = get(f'{base_url}{regex_one_query}', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_two_results = get(f'{base_url}{regex_two_query}', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_one_results = get(f'{base_url}{exrobotos_group_one}', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_two_results = get(f'{base_url}{exrobotos_group_two}', headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-laptop",
   "metadata": {},
   "source": [
    "#### Parse results from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse results from json file\n",
    "regex_one_file = ''\n",
    "regex_two_file = ''\n",
    "exrobotos_group_one_file = ''\n",
    "exrobotos_group_two_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(regex_one_file, 'r') as file:\n",
    "    regex_one_results = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(regex_two_file, 'r') as file:\n",
    "    regex_two_results = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(exrobotos_group_one_file, 'r') as file:\n",
    "    group_one_results = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(exrobotos_group_two_file, 'r') as file:\n",
    "    group_two_results = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'REGEX 1 results: {regex_one_results[\"total\"]}')\n",
    "print(f'REGEX 2 results: {regex_two_results[\"total\"]}')\n",
    "print(f'ExRobotos Group 1 results: {group_one_results[\"total\"]}')\n",
    "print(f'ExRobotos Group 2 results: {group_two_results[\"total\"]}')\n",
    "\n",
    "# Combine data\n",
    "recaptcha_results = regex_one_results['results'] + regex_two_results['results']\n",
    "exrobotos_results = group_one_results[\"results\"] + group_two_results[\"results\"]\n",
    "total_recaptcha = len(recaptcha_results)\n",
    "total_exrobotos = len(exrobotos_results)\n",
    "print(f'Total reCAPTCHA results: {total_recaptcha}')\n",
    "print(f'Total ExRobotos results: {total_exrobotos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-healing",
   "metadata": {},
   "source": [
    "## Output Final Destination Phishing Domains/URLs\n",
    "\n",
    "**Enter output files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_recaptcha_file = 'phish_domains_abusing_recaptcha.txt'\n",
    "output_exrobotos_file_one = 'phish_urls_exrobotos_group_one.txt'\n",
    "output_exrobotos_file_two = 'phish_urls_exrobotos_group_two.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reCAPTCHA\n",
    "# Dedup domains\n",
    "recaptcha_domains = set()\n",
    "for i in recaptcha_results:\n",
    "    recaptcha_domains.add(i['page']['domain'])\n",
    "\n",
    "print(f'Total phishing domains abusing reCAPTCHA: {len(recaptcha_domains)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_recaptcha_file, 'w+') as file:\n",
    "    for domain in recaptcha_domains:\n",
    "        file.write(f\"{domain}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExRobotos\n",
    "# Dedup urls\n",
    "exrobotos_urls = set()\n",
    "for i in group_one_results[\"results\"]:\n",
    "    exrobotos_urls.add(i['page']['url'])\n",
    "print(f'Total phishing urls using ExRobotos Phishing Kit: {len(exrobotos_urls)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_exrobotos_file_one, 'w+') as file:\n",
    "    for url in exrobotos_urls:\n",
    "        file.write(f\"{url}\\n\")\n",
    "\n",
    "# Dedup urls\n",
    "exrobotos_urls = set()\n",
    "for i in group_two_results[\"results\"]:\n",
    "    exrobotos_urls.add(i['page']['url'])\n",
    "print(f'Total phishing urls using ExRobotos Phishing Kit: {len(exrobotos_urls)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_exrobotos_file_two, 'w+') as file:\n",
    "    for url in exrobotos_urls:\n",
    "        file.write(f\"{url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-shell",
   "metadata": {},
   "source": [
    "**Optional: output phish domains/URLs with datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_recaptcha_file = 'phish_domains_abusing_recaptcha_with_datetime.csv'\n",
    "output_exrobotos_file_one = 'phish_urls_exrobotos_group_one_with_datetime.csv'\n",
    "output_exrobotos_file_two = 'phish_urls_exrobotos_group_two_with_datetime.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_and_page_urls = []\n",
    "for i in recaptcha_results:\n",
    "    tasks_and_page_urls.append([i['task']['time'], i['page']['domain']])\n",
    "df = pd.DataFrame(tasks_and_page_urls, columns=['Task Time', 'Domain'])\n",
    "\n",
    "print(f'Total results: {len(tasks_and_page_urls)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_recaptcha_file, 'w+') as file:\n",
    "    file.write(df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_and_page_urls = []\n",
    "for i in group_one_results[\"results\"]:\n",
    "    tasks_and_page_urls.append([i['task']['time'], i['page']['url']])\n",
    "df = pd.DataFrame(tasks_and_page_urls, columns=['Task Time', 'url'])\n",
    "\n",
    "print(f'Total results: {len(tasks_and_page_urls)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_exrobotos_file_one, 'w+') as file:\n",
    "    file.write(df.to_csv(index=False))\n",
    "\n",
    "tasks_and_page_urls = []\n",
    "for i in group_two_results[\"results\"]:\n",
    "    tasks_and_page_urls.append([i['task']['time'], i['page']['url']])\n",
    "df = pd.DataFrame(tasks_and_page_urls, columns=['Task Time', 'url'])\n",
    "\n",
    "print(f'Total results: {len(tasks_and_page_urls)}')\n",
    "\n",
    "# Write to file\n",
    "with open(output_exrobotos_file_two, 'w+') as file:\n",
    "    file.write(df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-seven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
